{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Searching companies by what they do",
   "id": "626616ebf47fbbaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "This notebook shows how we can use embeddings to generate vector representations of companies and then use these vectors to find companies based on what they do.\n",
    "\n",
    "The goal of this tutorial is not to develop the best possible method but to explore whether embedding company parameters can generate something useful.\n",
    "\n",
    "I also compared this approach with a keyword search to see how it performs. It was quite interesting to see the results side by side and judge."
   ],
   "id": "217b498c5ab31c22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Install opensearch\n",
    "\n",
    "We will use opensearch to store the data and search for companies. We will use the opensearch-dsl library to interact with opensearch.\n",
    "To do that and make this more reproducible, we will use docker to install opensearch."
   ],
   "id": "18cb4a191e6504d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:42:47.103315Z",
     "start_time": "2024-07-10T01:42:43.448897Z"
    }
   },
   "cell_type": "code",
   "source": "!docker pull opensearchproject/opensearch:2",
   "id": "f18067b38a3beee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: Pulling from opensearchproject/opensearch\r\n",
      "Digest: sha256:1a6d62f4ff2215f66792362a56c64cea29ff6cbe700f95881857f045a6fea3c9\r\n",
      "Status: Image is up to date for opensearchproject/opensearch:2\r\n",
      "docker.io/opensearchproject/opensearch:2\r\n",
      "\u001B[1m\r\n",
      "What's next:\u001B[0m\r\n",
      "    View a summary of image vulnerabilities and recommendations â†’ \u001B[36mdocker scout quickview opensearchproject/opensearch:2\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A lot of the steps in this notebook are manual and can be automated. However, I wanted to keep it simple and show the steps involved in setting up the system.",
   "id": "d7f0851a84a448a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:42:50.790547Z",
     "start_time": "2024-07-10T01:42:49.874848Z"
    }
   },
   "cell_type": "code",
   "source": "!docker run -d -p 9200:9200 -p 9600:9600 -e \"discovery.type=single-node\" -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=opensearch-ABN-ameer-2024!\" opensearchproject/opensearch:2",
   "id": "384dab631509b08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3c9209c06805ce2c51cc34a62d71beec941366fe86d6c53ad68082b723660a3d\r\n",
      "docker: Error response from daemon: driver failed programming external connectivity on endpoint peaceful_jepsen (9c9672b940fa799a1e65d1e15f1567e1e9732a1c4c45cf5aef4cff5d0b7d80b7): Bind for 0.0.0.0:9600 failed: port is already allocated.\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install the required libraries",
   "id": "1339d337c4924a38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:42:53.997319Z",
     "start_time": "2024-07-10T01:42:52.248229Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -r requirements.txt",
   "id": "4ffb97a1aa85918e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4==4.12.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.12.3)\r\n",
      "Requirement already satisfied: lxml==5.2.2 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (5.2.2)\r\n",
      "Requirement already satisfied: opensearch-dsl==2.1.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.1.0)\r\n",
      "Requirement already satisfied: sentence-transformers==3.0.1 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.0.1)\r\n",
      "Requirement already satisfied: streamlit==1.36.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.36.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4==4.12.3->-r requirements.txt (line 1)) (2.5)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from opensearch-dsl==2.1.0->-r requirements.txt (line 3)) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil in ./venv/lib/python3.9/site-packages (from opensearch-dsl==2.1.0->-r requirements.txt (line 3)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: opensearch-py>=2.2.0 in ./venv/lib/python3.9/site-packages (from opensearch-dsl==2.1.0->-r requirements.txt (line 3)) (2.6.0)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (4.42.3)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (2.3.1)\r\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (1.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (0.23.4)\r\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.9/site-packages (from sentence-transformers==3.0.1->-r requirements.txt (line 4)) (10.4.0)\r\n",
      "Requirement already satisfied: altair<6,>=4.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (5.3.0)\r\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (1.8.2)\r\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (5.3.3)\r\n",
      "Requirement already satisfied: click<9,>=7.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (8.1.7)\r\n",
      "Requirement already satisfied: packaging<25,>=20 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (24.1)\r\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (2.2.2)\r\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (5.27.2)\r\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (16.1.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (2.32.3)\r\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (13.7.1)\r\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (8.5.0)\r\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (0.10.2)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (4.12.2)\r\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (3.1.43)\r\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (0.9.1)\r\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./venv/lib/python3.9/site-packages (from streamlit==1.36.0->-r requirements.txt (line 5)) (6.4.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (3.1.4)\r\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (4.23.0)\r\n",
      "Requirement already satisfied: toolz in ./venv/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (0.12.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.9/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.36.0->-r requirements.txt (line 5)) (4.0.11)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (3.15.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (2024.6.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (6.0.1)\r\n",
      "Requirement already satisfied: certifi>=2022.12.07 in ./venv/lib/python3.9/site-packages (from opensearch-py>=2.2.0->opensearch-dsl==2.1.0->-r requirements.txt (line 3)) (2024.7.4)\r\n",
      "Requirement already satisfied: Events in ./venv/lib/python3.9/site-packages (from opensearch-py>=2.2.0->opensearch-dsl==2.1.0->-r requirements.txt (line 3)) (0.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.26.18 in ./venv/lib/python3.9/site-packages (from opensearch-py>=2.2.0->opensearch-dsl==2.1.0->-r requirements.txt (line 3)) (1.26.19)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit==1.36.0->-r requirements.txt (line 5)) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit==1.36.0->-r requirements.txt (line 5)) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit==1.36.0->-r requirements.txt (line 5)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit==1.36.0->-r requirements.txt (line 5)) (3.7)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit==1.36.0->-r requirements.txt (line 5)) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit==1.36.0->-r requirements.txt (line 5)) (2.18.0)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (3.2.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (2024.5.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (0.19.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (3.5.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.36.0->-r requirements.txt (line 5)) (5.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (2.1.5)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.36.0->-r requirements.txt (line 5)) (0.19.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.36.0->-r requirements.txt (line 5)) (0.1.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers==3.0.1->-r requirements.txt (line 4)) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create index",
   "id": "9135a4632775c64f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:42:55.387417Z",
     "start_time": "2024-07-10T01:42:55.284243Z"
    }
   },
   "cell_type": "code",
   "source": "from opensearchpy import OpenSearch",
   "id": "6099f4e25dd7586b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Disable many features of OpenSearch to allow querying it without worrying about SSL and certificate issues, which is useful for local development environments.",
   "id": "3c46e3df88ba497b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:42:57.043575Z",
     "start_time": "2024-07-10T01:42:57.039391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenSearch('http://localhost:9200',  http_auth = ('admin','opensearch-ABN-ameer-2024!'), use_ssl = True, verify_certs = False,    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False)"
   ],
   "id": "28c566a27061e5d8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:42:58.516270Z",
     "start_time": "2024-07-10T01:42:58.014086Z"
    }
   },
   "cell_type": "code",
   "source": "client.indices.create(index='abn', ignore=400)",
   "id": "fcd0707d47d2e20f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'root_cause': [{'type': 'resource_already_exists_exception',\n",
       "    'reason': 'index [abn/9OaUcTDqRl2oVjSCQ6uUEA] already exists',\n",
       "    'index': 'abn',\n",
       "    'index_uuid': '9OaUcTDqRl2oVjSCQ6uUEA'}],\n",
       "  'type': 'resource_already_exists_exception',\n",
       "  'reason': 'index [abn/9OaUcTDqRl2oVjSCQ6uUEA] already exists',\n",
       "  'index': 'abn',\n",
       "  'index_uuid': '9OaUcTDqRl2oVjSCQ6uUEA'},\n",
       " 'status': 400}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Double check we can search the index",
   "id": "4a0a49c7b9681d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:43:00.224613Z",
     "start_time": "2024-07-10T01:43:00.208055Z"
    }
   },
   "cell_type": "code",
   "source": "client.search(index='abn')",
   "id": "f6c58a8ebe280f52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 6,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 0, 'relation': 'eq'},\n",
       "  'max_score': None,\n",
       "  'hits': []}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Downloading the data\n",
    "\n",
    "The data is extracted from the ABN bulk data and is stored in the test_data folder. For the sake of simplicity, I have only extracted the company name and the state of the company. I also kept the data small to make it easier to work with. A sample of the data is available in the test_data folder.\n",
    "\n",
    "If you would like to test with more data, you can grab the entire dataset from the ABN website and extract it to the test_data folder."
   ],
   "id": "b0ad6cddce268b6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing the infrastructure to embedding ",
   "id": "4cb39c823fcaca1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Choosing which model to use can be a daunting task, so I simply picked the best model in the benchmark that has a nice memory footprint and can be used on a local machine. I chose the e5-small-v2 model. I have used it before, and it was easy to download and use directly from within Sentence Transformers. Feel free to use any other model if you prefer.",
   "id": "cd0ea10e2585815e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:43:05.786618Z",
     "start_time": "2024-07-10T01:43:03.406303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_encoder(model_name=\"intfloat/e5-small-v2\"):\n",
    "    return SentenceTransformer(model_name)"
   ],
   "id": "74b742a20bbad4cd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aalbahem/workspace/me/opensearch-abn/venv/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the model",
   "id": "77de2e4112ab9f3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:43:12.218846Z",
     "start_time": "2024-07-10T01:43:07.319592Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_model = get_encoder(\"intfloat/e5-small-v2\")",
   "id": "1ac5a90dbd3f7c3a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare opensearch settings",
   "id": "e3b3b6a7088801fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:43:12.665637Z",
     "start_time": "2024-07-10T01:43:12.220289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the mapping for the index\n",
    "index_settings = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True\n",
    "  }\n",
    "}\n",
    "\n",
    "index_mappings = {\n",
    "    \"properties\": {\n",
    "      \"text-field\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"company_embeddings\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 384,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"space_type\": \"l2\",\n",
    "          \"engine\": \"lucene\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    client.indices.delete(index='abn', ignore=400)\n",
    "except:\n",
    "    pass\n",
    "client.indices.create(index='abn', ignore=400)\n",
    "\n",
    "client.indices.close(index='abn')\n",
    "# Update the index with the defined mapping\n",
    "client.indices.put_settings(index='abn', body=index_settings)\n",
    "client.indices.put_mapping(index='abn', body=index_mappings)\n",
    "client.indices.open(index='abn')\n",
    "client.indices.get_settings(index='abn')\n",
    "client.indices.get_mapping(index='abn')"
   ],
   "id": "97c0ab6508253842",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abn': {'mappings': {'properties': {'company_embeddings': {'type': 'knn_vector',\n",
       "     'dimension': 384,\n",
       "     'method': {'engine': 'lucene',\n",
       "      'space_type': 'l2',\n",
       "      'name': 'hnsw',\n",
       "      'parameters': {}}},\n",
       "    'text-field': {'type': 'text'}}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Ingest data"
   ],
   "id": "bafececde7417afd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will walk through the test_data folder and parse the data. We will then encode the company name and store it in the OpenSearch index.\n",
    "\n",
    "Note that OpenSearch provides the ability to generate embeddings as part of its pipeline, but for the sake of simplicity, I am generating the embeddings before storing the data in OpenSearch."
   ],
   "id": "4f9b6edf2125e0a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:43:16.086817Z",
     "start_time": "2024-07-10T01:43:15.997849Z"
    }
   },
   "cell_type": "code",
   "source": "from abn_bulk_data_parser import walk_and_parse",
   "id": "e4b10c2efa91c876",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-10T01:43:18.372898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for company in walk_and_parse(\"test_data\"):\n",
    "    company['company_embeddings'] = embedding_model.encode(company['company_name'],normalize_embeddings=True).tolist()\n",
    "    \n",
    "    # Ideally, we can do batch, but for the sake of simplicity, we will do one by one.\n",
    "    response = client.index(\"abn\",body=company)"
   ],
   "id": "acfaddbb2b8a3cb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client.search_template(index='abn',body=\n",
    "{\n",
    "  \"source\": { \n",
    "            \"query\":{\"match\":{\"company_name\": \"{{company_name}}\"}}},\n",
    "  \"params\": {\n",
    "    \"company_name\": \"TESTER\"\n",
    "  }\n",
    "}\n",
    ")"
   ],
   "id": "f6e8c76df74322fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparing some search templates",
   "id": "4e7d5ecd94590519"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:51:14.063687Z",
     "start_time": "2024-07-09T14:51:13.968696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client.put_script ('company_keyword_search_template',\n",
    "{\n",
    "  \"script\": {\n",
    "   \"lang\": \"mustache\",\n",
    "   \"source\": { \n",
    "            \"query\":{\"match\":{\"company_name\": \"{{company_name}}\"}}},\n",
    "   \"params\": {\n",
    "    \"company_name\": \"TESTER\"\n",
    "   }\n",
    "  }\n",
    "})"
   ],
   "id": "f1fa928280a8d612",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 306
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client.put_script ('company_knn_search_template',\n",
    "{\n",
    "  \"script\": {\n",
    "    \"lang\": \"mustache\",\n",
    "    \"source\": {\n",
    "      \"from\": \"{{from}}{{^from}}0{{/from}}\",\n",
    "      \"size\": \"{{size}}{{^size}}10{{/size}}\",\n",
    "      \"query\": {\n",
    "            \"knn\": {\n",
    "                \"company_embeddings\": {\n",
    "                    \"vector\": \"{{query_embeddings}}\",\n",
    "                    \"k\": 10\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"params\": {\n",
    "      \"query_embeddings\": []\n",
    "    }\n",
    "  }\n",
    "})\n"
   ],
   "id": "ad249a6eb65b9d2b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building the app\n",
    "I have created a simple Streamlit app to compare the search results from the keyword search and the embedding search. The app is available in the st_compare_app.py file. The command below launches the app."
   ],
   "id": "116f85b85502f8e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!streamlit run st_compare_app.py",
   "id": "1582cfa6f118054f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Search examples\n",
    "\n",
    "Try searching for following queries that I used and found the results quite interesting:\n",
    "- Religious organisations\n",
    "- Hot Coals Catering\n",
    "- Catering"
   ],
   "id": "d9ffebbed1ee4177"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "The embedding search is quite interesting and can be used to find similar companies based on what they do. The keyword search is quite useful for finding companies based on their names. The embedding search can be further refined by using a more sophisticated model and by using more data. The keyword search can be improved by using a more sophisticated search engine like ElasticSearch or OpenSearch.\n",
    "\n",
    "One thing that found interesting if we can find a company description (if we link to another dataset) and use that as a search query. This can be quite useful in finding companies that do similar things. "
   ],
   "id": "4195e0a8e45d0a8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
